# Dino AI - Platform Independent AI System

ğŸ¦• A versatile AI system that can work with or without ROS, with or without physical embodiment.

## Overview

Dino AI is designed as a **platform-independent AI system** that provides intelligent robot control through abstract interfaces. It can work equally well on:

- ğŸ¤– **Physical robots** (via ROS adapters)
- ğŸ® **Simulation environments** (built-in simulation)  
- ğŸ’¬ **Text-only systems** (pure conversation AI)
- â˜ï¸ **Cloud deployments** (no hardware needed)

## Key Features

- **Platform Independence**: Core AI logic works across different platforms
- **Capability Detection**: Automatically adapts to available hardware
- **Graceful Degradation**: Works even when some capabilities are missing
- **Modular Architecture**: Easy to add new platforms and capabilities
- **ROS Integration**: Optional ROS adapter for robotics platforms

## Quick Start

### Installation

```bash
# Basic installation
pip install dino-ai

# With ROS support
pip install dino-ai[ros]

# With AI capabilities
pip install dino-ai[ai]

# Full installation
pip install dino-ai[all]
```

### Usage Examples

#### 1. Text-Only AI (No Hardware)
```bash
dino-ai --platform null
```
Perfect for testing AI logic or deploying as a chatbot.

#### 2. Simulation Mode (Development)
```bash
dino-ai --platform simulation
```
Full robot simulation for development and testing.

#### 3. ROS Robot Control
```bash
dino-ai --platform ros
```
Control real robots via ROS2.

#### 4. Interactive Modes
```bash
# Text interaction
dino-ai --mode interactive

# Demo mode
dino-ai --mode demo

# With speech (if available)
dino-ai --speech
```

## Platform Capabilities

| Capability    | Null | Simulation | ROS |
|---------------|------|------------|-----|
| Conversation  | âœ…   | âœ…         | âœ…  |
| Navigation    | âŒ   | âœ… (sim)   | âœ…  |
| Manipulation  | âŒ   | âœ… (sim)   | âœ…  |
| Vision        | âŒ   | âœ… (sim)   | âœ…  |
| Speech        | âš ï¸   | âœ… (text)  | âœ…  |

## Example Conversation

```
You: Hello Dino
ğŸ¦•: Hello! I'm Dino AI running on a Simulation platform with these 
    capabilities: navigation, manipulation, vision, speech. How can I help?

You: What can you do?
ğŸ¦•: I can navigate and move around, control robotic arms and grippers, 
    see and analyze images. I'm also great at conversation!

You: Move forward
ğŸ¦•: Moving forward 1 meter
[Platform adapter executes movement]

You: What do you see?
ğŸ¦•: I can see: A room with colorful geometric shapes. There's a red 
    rectangle on the left, a green circle in the center...
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            User Interface               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             Dino Brain                  â”‚
â”‚         (Core AI Logic)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Abstract Interfaces             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ROS Adapter     â”‚ Simulation â”‚ Null     â”‚
â”‚ (Real Robot)    â”‚ Adapter    â”‚ Adapter  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Development

### Creating Custom Adapters

```python
from dino_ai.core.interfaces import PlatformInterface

class MyCustomAdapter(PlatformInterface):
    def initialize(self, config):
        # Initialize your platform
        return True
    
    def get_available_capabilities(self):
        return ["my_capability"]
```

### Adding New Capabilities

```python
from dino_ai.core.interfaces import NavigationInterface

class MyNavigationAdapter(NavigationInterface):
    def get_current_pose(self):
        # Return current robot pose
        pass
    
    def navigate_to_pose(self, pose):
        # Navigate to target pose
        pass
```

## Requirements

### Core (Always Required)
- Python 3.8+
- numpy
- pillow

### Optional Dependencies
- **ROS**: rclpy, ROS2 message packages
- **AI**: langchain, langgraph, openai/anthropic
- **Vision**: opencv-python, torch, transformers  
- **Speech**: SpeechRecognition, pyttsx3, faster-whisper

## Configuration

Dino AI automatically detects available capabilities and adapts accordingly. For advanced configuration:

```python
config = {
    "log_level": "INFO",
    "vision_model": "moondream",
    "speech_enabled": True
}

platform = create_simulation_platform()
platform.initialize(config)
dino = DinoBrain(platform)
```

## Use Cases

### ğŸ¤– **Robotics Development**
- Develop AI logic without hardware
- Test in simulation before deployment
- Easy transition from sim to real robot

### ğŸ’¬ **Chatbot Deployment** 
- Deploy as pure conversation AI
- No robotics dependencies needed
- Cloud-friendly architecture

### ğŸ”¬ **Research & Education**
- Platform-independent AI research
- Easy to understand architecture
- Extensible for custom platforms

### ğŸ­ **Production Systems**
- Reliable robotics control
- Graceful error handling
- Platform flexibility

## License

MIT License - see LICENSE file for details.

## Contributing

Contributions welcome! Please see CONTRIBUTING.md for guidelines.

## Support

- ğŸ“– Documentation: See README and code comments
- ğŸ› Issues: GitHub Issues  
- ğŸ’¬ Discussions: GitHub Discussions