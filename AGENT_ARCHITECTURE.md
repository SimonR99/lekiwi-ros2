# Dino AI - Advanced Agent Architecture

## Overview

Dino AI employs a **multi-agent architecture** with specialized agents that collaborate to handle complex robotics tasks. The system uses **LangGraph** for orchestration and **capability-based routing** to ensure optimal performance across different platforms.

## Core Architecture Principles

### 1. **Agent Specialization**
Each agent is highly specialized for specific domains, leading to better performance and maintainability.

### 2. **Collaborative Intelligence**
Agents can work together on complex tasks that require multiple capabilities.

### 3. **Dynamic Routing**
Tasks are intelligently routed to the most appropriate agent based on context and platform capabilities.

### 4. **State Management**
Shared state ensures consistency across agents and enables complex multi-step operations.

## Agent System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface Layer                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Voice Interface â”‚ Text Interface  â”‚ API Interface              â”‚
â”‚ (Speech Agent)  â”‚ (All Agents)    â”‚ (Server Mode)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LangGraph Orchestration                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Task Coordinator                           â”‚    â”‚
â”‚  â”‚  â€¢ Intent Analysis & Classification                     â”‚    â”‚
â”‚  â”‚  â€¢ Agent Selection & Routing                           â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Multi-agent Workflow Coordination                 â”‚    â”‚
â”‚  â”‚  â€¢ State Management & Memory                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Specialized Agents                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Conversation â”‚ Navigation  â”‚Manipulation â”‚   Vision    â”‚ System  â”‚
â”‚   Agent     â”‚   Agent     â”‚   Agent     â”‚   Agent     â”‚ Agent   â”‚
â”‚             â”‚             â”‚             â”‚             â”‚         â”‚
â”‚â€¢ Chat & QA  â”‚â€¢ Path Plan  â”‚â€¢ Motion     â”‚â€¢ Scene      â”‚â€¢ Health â”‚
â”‚â€¢ Context    â”‚â€¢ Obstacle   â”‚  Planning   â”‚  Analysis   â”‚â€¢ Status â”‚
â”‚â€¢ Memory     â”‚  Avoidance  â”‚â€¢ IK/FK      â”‚â€¢ Object     â”‚â€¢ Debug  â”‚
â”‚â€¢ Personalityâ”‚â€¢ Mapping    â”‚â€¢ Safety     â”‚  Detection  â”‚â€¢ Config â”‚
â”‚             â”‚â€¢ Waypoints  â”‚â€¢ Grasping   â”‚â€¢ Visual Q&A â”‚â€¢ Logs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Capability Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Navigation      â”‚ Manipulation    â”‚ Vision      â”‚ Speech      â”‚
â”‚ Interface       â”‚ Interface       â”‚ Interface   â”‚ Interface   â”‚
â”‚â€¢ get_pose()     â”‚â€¢ move_arm()     â”‚â€¢ get_img()  â”‚â€¢ speak()    â”‚
â”‚â€¢ navigate()     â”‚â€¢ get_joints()   â”‚â€¢ analyze()  â”‚â€¢ listen()   â”‚
â”‚â€¢ plan_path()    â”‚â€¢ gripper()      â”‚â€¢ detect()   â”‚â€¢ tts_ctrl() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Platform Adapters                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ROS Adapter     â”‚ Simulation      â”‚ Cloud/Null Adapter        â”‚
â”‚â€¢ Real Robot     â”‚ Adapter         â”‚â€¢ Text-only Systems         â”‚
â”‚â€¢ Nav2/MoveIt    â”‚â€¢ Testing        â”‚â€¢ API-only Mode             â”‚
â”‚â€¢ Hardware I/O   â”‚â€¢ Development    â”‚â€¢ Headless Operation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Agent Specifications

### 1. **Conversation Agent** ğŸ—£ï¸

**Purpose**: Handle natural language conversation, context management, and general Q&A

**Responsibilities**:
- Maintain conversation context and memory
- Handle greetings, farewells, and general chat
- Provide help and explain system capabilities
- Manage user preferences and personality
- Route complex queries to specialist agents

**Key Features**:
- Long-term conversation memory
- Personality consistency
- Context-aware responses
- Natural dialogue flow

**Example Interactions**:
```
User: "Hello, how are you today?"
Agent: Manages greeting, updates conversation state, provides personalized response

User: "What did we talk about yesterday?"
Agent: Retrieves conversation history, summarizes previous interactions
```

### 2. **Navigation Agent** ğŸš—

**Purpose**: Handle all movement and spatial reasoning tasks

**Responsibilities**:
- Path planning and obstacle avoidance
- Spatial reasoning and mapping
- Movement execution and monitoring
- Location awareness and waypoint management

**Key Features**:
- Multi-modal path planning (shortest, safest, most efficient)
- Dynamic obstacle avoidance
- Semantic location understanding
- Movement safety validation

**Example Interactions**:
```
User: "Go to the kitchen and avoid the chairs"
Agent: Plans path, identifies obstacles, executes safe navigation

User: "Where am I right now?"
Agent: Provides current location with spatial context
```

### 3. **Manipulation Agent** ğŸ¦¾

**Purpose**: Handle robotic arm control and manipulation tasks

**Responsibilities**:
- Motion planning for robotic arms
- Object grasping and manipulation
- Safety constraint enforcement
- Precision positioning and coordination

**Key Features**:
- Advanced inverse kinematics
- Collision detection and avoidance
- Adaptive grasping strategies
- Force feedback integration

**Example Interactions**:
```
User: "Pick up the red cup carefully"
Agent: Analyzes grasp options, plans arm trajectory, executes gentle pickup

User: "Move your arm to a safe position"
Agent: Calculates safe pose, moves arm away from obstacles
```

### 4. **Vision Agent** ğŸ‘ï¸

**Purpose**: Handle visual perception and scene understanding

**Responsibilities**:
- Scene analysis and description
- Object detection and recognition
- Visual question answering
- Image processing and enhancement

**Key Features**:
- Multi-modal vision models (Moondream, CLIP, etc.)
- Real-time object tracking
- Semantic scene understanding
- Visual reasoning capabilities

**Example Interactions**:
```
User: "What do you see on the table?"
Agent: Analyzes current view, identifies objects, describes spatial relationships

User: "Is there a bottle in the scene?"
Agent: Performs object detection, confirms presence and location
```

### 5. **System Agent** âš™ï¸

**Purpose**: Handle system monitoring, diagnostics, and configuration

**Responsibilities**:
- Health monitoring and diagnostics
- Performance optimization
- Configuration management
- Error handling and recovery

**Key Features**:
- Real-time system metrics
- Predictive maintenance
- Automated error recovery
- Performance analytics

**Example Interactions**:
```
User: "Check your system status"
Agent: Reports health metrics, current capabilities, any issues

User: "Why are you moving slowly?"
Agent: Analyzes performance, identifies bottlenecks, suggests solutions
```

## Task Coordination & Routing

### 1. **Intent Classification**

The Task Coordinator analyzes incoming requests and classifies them:

```python
class TaskCoordinator:
    def classify_intent(self, message: str) -> AgentRoute:
        # Multi-level classification
        primary_intent = self.classify_primary(message)
        secondary_intents = self.classify_secondary(message)
        context = self.get_conversation_context()
        
        return AgentRoute(
            primary_agent=primary_intent,
            supporting_agents=secondary_intents,
            context=context,
            confidence=self.calculate_confidence()
        )
```

### 2. **Multi-Agent Workflows**

Complex tasks often require multiple agents:

```python
# Example: "Go to the kitchen and pick up the red cup"
workflow = SequentialWorkflow([
    NavigationTask(agent="navigation", goal="kitchen"),
    VisionTask(agent="vision", target="red cup"),
    ManipulationTask(agent="manipulation", action="pickup"),
    ConversationTask(agent="conversation", response="task_complete")
])
```

### 3. **State Sharing**

Agents share state through a centralized state manager:

```python
class SharedState:
    robot_pose: Pose
    scene_objects: List[DetectedObject]
    conversation_context: ConversationMemory
    current_task: Optional[Task]
    agent_status: Dict[str, AgentStatus]
```

## Advanced Agent Features

### 1. **Memory Systems**

**Short-term Memory**:
- Current conversation context
- Active task state
- Recent sensor data

**Long-term Memory**:
- User preferences and history
- Learned behaviors and patterns
- Environment maps and object models

**Episodic Memory**:
- Previous task executions
- Successful strategies
- Failure cases and lessons learned

### 2. **Learning & Adaptation**

**Reinforcement Learning**:
- Agents improve through experience
- Adaptive parameter tuning
- Performance optimization

**Few-shot Learning**:
- Quick adaptation to new scenarios
- User-specific behavior learning
- Domain transfer capabilities

### 3. **Safety & Constraints**

**Hard Constraints**:
- Physical safety limits
- Workspace boundaries
- Collision avoidance

**Soft Constraints**:
- Efficiency preferences
- User comfort zones
- Energy optimization

## Platform Adaptation

### 1. **Capability-Aware Routing**

Agents automatically adapt based on platform capabilities:

```python
def route_task(task: Task, platform: PlatformInterface) -> AgentWorkflow:
    if task.requires_navigation and not platform.has_navigation():
        return ConversationAgent.explain_limitation("navigation")
    
    if task.requires_vision and not platform.has_vision():
        return SimulatedVisionWorkflow()  # Fallback behavior
    
    return FullCapabilityWorkflow(task)
```

### 2. **Graceful Degradation**

When capabilities are missing, agents provide meaningful alternatives:

- **No Camera**: "I don't have vision, but I can help you describe what you're looking for"
- **No Arm**: "I can't physically manipulate objects, but I can guide you through the process"
- **No Navigation**: "I can't move, but I can help you plan the route"

## Implementation Benefits

### 1. **Modularity**
- Each agent can be developed, tested, and updated independently
- Easy to add new specialized agents
- Clear separation of concerns

### 2. **Scalability**
- Agents can run in parallel for better performance
- Easy to distribute across multiple machines
- Load balancing based on agent specialization

### 3. **Maintainability**
- Focused, specialized codebases
- Easier debugging and testing
- Clear responsibility boundaries

### 4. **Extensibility**
- New agents can be added without modifying existing ones
- Platform adapters can support agent-specific optimizations
- Easy integration of new AI models and techniques

## Example Multi-Agent Scenarios

### Scenario 1: "Clean up the table"

1. **Vision Agent**: Analyzes table, identifies objects and clutter
2. **Navigation Agent**: Plans approach to table
3. **Manipulation Agent**: Picks up objects one by one
4. **Vision Agent**: Confirms objects are properly placed
5. **Conversation Agent**: Reports completion and asks for feedback

### Scenario 2: "Find my keys"

1. **Conversation Agent**: Clarifies what the keys look like
2. **Navigation Agent**: Plans search pattern through house
3. **Vision Agent**: Analyzes each room for key objects
4. **Navigation Agent**: Moves to promising locations
5. **Conversation Agent**: Reports findings and guides user

### Scenario 3: "Teach me to cook pasta"

1. **Conversation Agent**: Asks about skill level and preferences
2. **Vision Agent**: Identifies available ingredients and tools
3. **Manipulation Agent**: Demonstrates stirring motions
4. **Conversation Agent**: Provides step-by-step guidance
5. **System Agent**: Sets timers and monitors progress

## Future Enhancements

### 1. **Meta-Learning Agent**
- Learns how to coordinate other agents more effectively
- Adapts routing strategies based on success rates
- Optimizes multi-agent workflows

### 2. **Emotional Intelligence Agent**
- Recognizes user emotional state
- Adapts behavior for better user experience
- Provides emotional support and companionship

### 3. **Planning Agent**
- Long-term task planning and scheduling
- Resource allocation and optimization
- Proactive task suggestion

### 4. **Security Agent**
- Monitors for potential security threats
- Validates commands for safety
- Manages access control and permissions

## MCP (Model Context Protocol) Integration

### 1. **Dynamic Tool Ecosystem**

Dino AI supports **MCP servers** for dynamic tool loading and external service integration:

```python
class MCPClient:
    def __init__(self, config: MCPConfig):
        self.servers = MultiServerMCPClient(config)
        self.available_tools = {}
    
    async def discover_tools(self) -> List[Tool]:
        """Dynamically discover tools from MCP servers"""
        tools = await self.servers.get_tools()
        self.available_tools = {tool.name: tool for tool in tools}
        return tools
    
    async def call_tool(self, name: str, args: dict) -> Any:
        """Execute tool via MCP"""
        tool = self.available_tools.get(name)
        if tool:
            return await tool.ainvoke(args)
        raise ToolNotFoundError(f"Tool {name} not available")
```

### 2. **MCP Server Categories**

**Speech & Audio Services**:
- Text-to-Speech (Piper, Coqui, ElevenLabs)
- Speech Recognition (Whisper, Azure)
- Audio processing and effects

**Vision & Perception**:
- Object detection services
- Image generation (DALLE, Midjourney)
- OCR and document processing

**External APIs**:
- Weather services
- IoT device control
- Database integrations
- Web search and scraping

**Mathematical & Scientific**:
- Calculation engines
- Data analysis tools
- Simulation interfaces

### 3. **Agent-MCP Integration**

Agents can dynamically acquire new capabilities through MCP:

```python
class EnhancedAgent:
    def __init__(self, base_capabilities: List[str]):
        self.base_capabilities = base_capabilities
        self.mcp_client = MCPClient()
        self.dynamic_tools = {}
    
    async def expand_capabilities(self):
        """Discover and integrate MCP tools"""
        available_tools = await self.mcp_client.discover_tools()
        
        # Route tools to appropriate agents
        for tool in available_tools:
            if "speech" in tool.name.lower():
                self.assign_to_conversation_agent(tool)
            elif "vision" in tool.name.lower():
                self.assign_to_vision_agent(tool)
            elif "calculate" in tool.name.lower():
                self.assign_to_system_agent(tool)
```

### 4. **LangGraph Tool Integration**

MCP tools seamlessly integrate with LangGraph workflows:

```python
# Example: Math calculation with external MCP server
workflow = StateGraph(AgentState)

@workflow.node("calculate")
async def math_node(state: AgentState):
    # Use MCP math server for complex calculations
    result = await mcp_client.call_tool("multiply", {
        "a": state.operand_1,
        "b": state.operand_2
    })
    return {"calculation_result": result}

# Example: Text-to-speech with MCP server
@workflow.node("speak")
async def speak_node(state: AgentState):
    # Use MCP TTS server for speech output
    result = await mcp_client.call_tool("speak_text", {
        "text": state.response_text
    })
    return {"speech_completed": result["success"]}
```

### 5. **Configuration & Discovery**

MCP servers are configured via JSON and discovered automatically:

```json
{
  "mcpServers": {
    "math": {
      "command": "python",
      "args": ["mcp_servers/math_server.py"],
      "transport": "sse",
      "host": "127.0.0.1",
      "port": 8000
    },
    "tts": {
      "command": "python", 
      "args": ["mcp_servers/piper_server.py"],
      "transport": "sse",
      "host": "127.0.0.1",
      "port": 8001
    }
  }
}
```

### 6. **Benefits of MCP Integration**

**Modularity**:
- Add new capabilities without code changes
- External service integration
- Community-driven tool ecosystem

**Scalability**:
- Distribute compute-intensive tools to separate servers
- Load balancing across MCP instances
- Independent scaling of different capabilities

**Flexibility**:
- Hot-swap tools during runtime
- A/B test different implementations
- Gradual rollout of new features

**Security**:
- Isolated execution environments
- Permission-based tool access
- Audit trails for external calls

## Extended Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface Layer                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Voice Interface â”‚ Text Interface  â”‚ API Interface              â”‚
â”‚ (Speech Agent)  â”‚ (All Agents)    â”‚ (Server Mode)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LangGraph Orchestration                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Task Coordinator                           â”‚    â”‚
â”‚  â”‚  â€¢ Intent Analysis & Classification                     â”‚    â”‚
â”‚  â”‚  â€¢ Agent Selection & Routing                           â”‚    â”‚
â”‚  â”‚  â€¢ Multi-agent Workflow Coordination                   â”‚    â”‚  
â”‚  â”‚  â€¢ State Management & Memory                           â”‚    â”‚
â”‚  â”‚  â€¢ MCP Tool Discovery & Integration                    â”‚    â”‚ â† NEW
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Specialized Agents                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Conversation â”‚ Navigation  â”‚Manipulation â”‚   Vision    â”‚ System  â”‚
â”‚   Agent     â”‚   Agent     â”‚   Agent     â”‚   Agent     â”‚ Agent   â”‚
â”‚             â”‚             â”‚             â”‚             â”‚         â”‚
â”‚â€¢ Chat & QA  â”‚â€¢ Path Plan  â”‚â€¢ Motion     â”‚â€¢ Scene      â”‚â€¢ Health â”‚
â”‚â€¢ Context    â”‚â€¢ Obstacle   â”‚  Planning   â”‚  Analysis   â”‚â€¢ Status â”‚
â”‚â€¢ Memory     â”‚  Avoidance  â”‚â€¢ IK/FK      â”‚â€¢ Object     â”‚â€¢ Debug  â”‚
â”‚â€¢ Personalityâ”‚â€¢ Mapping    â”‚â€¢ Safety     â”‚  Detection  â”‚â€¢ Config â”‚
â”‚â€¢ MCP Tools  â”‚â€¢ MCP Tools  â”‚â€¢ MCP Tools  â”‚â€¢ MCP Tools  â”‚â€¢ Tools  â”‚ â† NEW
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Tool Layer                               â”‚ â† NEW
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Speech Services â”‚ Vision Services â”‚ External APIs              â”‚
â”‚â€¢ TTS (Piper)    â”‚â€¢ Object Detect  â”‚â€¢ Weather                   â”‚
â”‚â€¢ STT (Whisper)  â”‚â€¢ Image Gen      â”‚â€¢ IoT Control               â”‚
â”‚â€¢ Audio Effects  â”‚â€¢ OCR            â”‚â€¢ Web Search                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Math & Compute   â”‚ Data Services   â”‚ Communication              â”‚
â”‚â€¢ Calculations   â”‚â€¢ Database       â”‚â€¢ Email/SMS                 â”‚
â”‚â€¢ Simulations    â”‚â€¢ Analytics      â”‚â€¢ Notifications             â”‚
â”‚â€¢ Scientific     â”‚â€¢ File Processingâ”‚â€¢ Social Media              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Capability Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Navigation      â”‚ Manipulation    â”‚ Vision      â”‚ Speech      â”‚
â”‚ Interface       â”‚ Interface       â”‚ Interface   â”‚ Interface   â”‚
â”‚â€¢ get_pose()     â”‚â€¢ move_arm()     â”‚â€¢ get_img()  â”‚â€¢ speak()    â”‚
â”‚â€¢ navigate()     â”‚â€¢ get_joints()   â”‚â€¢ analyze()  â”‚â€¢ listen()   â”‚
â”‚â€¢ plan_path()    â”‚â€¢ gripper()      â”‚â€¢ detect()   â”‚â€¢ tts_ctrl() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Platform Adapters                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ROS Adapter     â”‚ Simulation      â”‚ Cloud/Null Adapter        â”‚
â”‚â€¢ Real Robot     â”‚ Adapter         â”‚â€¢ Text-only Systems         â”‚
â”‚â€¢ Nav2/MoveIt    â”‚â€¢ Testing        â”‚â€¢ API-only Mode             â”‚
â”‚â€¢ Hardware I/O   â”‚â€¢ Development    â”‚â€¢ Headless Operation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This advanced agent architecture with MCP integration provides a robust, scalable, and intelligent foundation for complex robotics applications while maintaining the platform independence that makes Dino AI so versatile.